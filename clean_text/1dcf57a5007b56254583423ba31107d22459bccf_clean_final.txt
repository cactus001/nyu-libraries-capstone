--- Page 0 ---
Peer Re view F ramework for Pr edictiv e Analytics in Humanitarian Response MODEL REPORT: Typhoon impact model 510 - An initiative of the Netherlands Red Cross August 2022

--- Page 1 ---
M o d e l R e p o r t : T y p h o o n i m p a c t m o d e l Back ground This document summarises the documentation and the ﬁnding of the peer review of the trigger used in OCHA’s Philippines Anticipatory Action framework for typhoons. The impact prediction model used as the basis for the trigger was developed by the Netherlands Red Cross 510 data and digital team, on behalf of the IFRC network and its partners. The model uses typhoon track and rainfall forecasts to predict the percentage of houses that will be severely damaged per municipality in the Philippines. OCHA Philippines used this model as a basis to begin a response before a typhoon hit, based on the predicted number of houses damaged in the regions of Bicol and Eastern Visayas. To ﬁnd out more about this application, please see the Anticipatory Action Framework for the Philippines . This peer review was conducted between September 2021 and July 2022. Main Findings and Recommendations The documentation regarding the model, its application and the review process can be found at the following links: ● The Model Card describes version 0 of the model and was completed in September ● The Model Evaluation Matrix was completed in October 2021 by a technical expert from Leiden University, and in February 2022 by the client. ● The Implementation Plan was completed in October It summarises the concrete actions that the model will trigger or inform as part of the 2021-2022 OCHA anticipatory action framework in the Philippines ● The Ethical Matrix aims to identify all stakeholders and potential issues regarding the intended use of the model. It was completed in November 2021 by an expert from the London School of Economics; and updated in July 2022. A summary of the main ﬁndings and recommendations is provided below. 1 Technical Re view

--- Page 2 ---
Intended Use ● The target of the model is P (#damaged houses > threshold t). Several combinations of Probability P and threshold t are used as a trigger for early action. Make a clear statement under which circumstance which combination is used. This will help with later evaluation of the model and transparency of its use. Model De velopment ● As mentioned in the ethical review, more information about the sources of the input data is desirable. The model should include information on how often the data sets are updated, and how often the model is retrained to reﬂect these updates. Model E valuation ● The model is compared against a damage curve that is currently used to estimate damage. Adjust this benchmark to whichever model or algorithm is used by the Philippine authorities to estimate damage. ● Specify how much variance in model performance is acceptable, i.e., with the model working on average better than the benchmark, how much extreme over / underestimation is acceptable for ﬁeld use. More speciﬁcally, indicate how robust the model performance is over different typhoons. Oper ational Readiness ● For every model version, make a model release and keep an updated list of associated input data. This will make reproducibility of earlier results easier and help keep track of the data sources (and whose responsibility those are). 2 Ethical Re view Inaccur acy The model performance scores for 2021 Typhoon Surigae are not reported. The rationale for using the given error / accuracy tool and not others is missing. The model does not perform well at predicting really low a nd really high damage. ● Recommendation: (1) Report latest error scores; (2) Contextualise the quality of the error scores in light of existing and relevant research; (3) Include the rationale for using a particular method of calculating error score as opposed to others. False Negativ es In the case of Typhoon Goni in 2020, the model did not predict an extreme event until only a few hours before landfall. ● Recommendation: If the model does have 100% weightage in the activation of the trigger, then the possibility of a false negative should be clear operationally, e.g., in the case of Typhoon Goni. This is of particular importance because we know that the model does perform well in cases of rapid intensiﬁcation or high damage scenarios.

--- Page 3 ---
Missing A ttributes The implementation model mentions a priority list based on poverty, gender, and building material, while the model uses poverty, hazard data, and building type where poverty is not disaggregated unless it follows some national standard of income levels to estimate poverty lines. ● Recommendation: Clarity is required on the relative importance of variables used, and consistency between the model and the implementation plan. There needs to be a distinction drawn between the model and how the outputs of the model are used. Clear delineation between input data (inclusion / exclusion criteria etc.); modelling process, output, and use; and validation / veriﬁcation, with a clear trail of documentation. Lead Times Lead time is the length of time between when a forecast is output and the occurrence of the shock that was forecasted. It is unclear the impact that forecast running time has on lead times for implementation. In the case of Typhoon Ursula (Phanfone) in 2019, the trigger was reached only 12 hours prior to landfall for which no humanitarian action could be planned. ● Recommendation: In the implementation plan, more clarity is required on potential operational impact of long lead times, especially with 100% weightage of model output for trigger activation. The effect of different lead times is unclear for the implementation. To quote one of the documents: 'It takes several hours for the forecast to run so the initial conditions are already often outdated'. Decision Suppor t Decision support concerns the extent to which action based on model output. ● Recommendation: Clarity is required in the implementation plan about weightage of model output on trigger activation, i.e., how much of the decision to act depends on the model output. If this is not 100%, then the other considerations should be described. ● Recommendation: Given the possibility of a false negative, operational readiness in case of model failure should be detailed in the implementation plan. Statistical Bias Statistical bias occurs when a model or statistic is not representative of the underlying population. In this model, different input datasets are used to model different typhoon scenarios, social vulnerability / poverty data is not suﬃciently disaggregated for evaluation, and the relative importance / weightage of the variables in the model is unclear. ● Recommendation: The model requires clear documentation of the different datasets used, particularly the rationale behind parameters used and their disaggregation, e.g., poverty index. Discrepancies on this front exist between the model card and implementation plan, and the model would beneﬁt from their harmonisation. It would also be useful to include these in an overview of the model development process, i.e., the relative weighting and importance of these variables, and how the model changes when they change.

--- Page 4 ---
Lack of Transpar ency The model is open source and has undergone technical review but is missing some documentation. ● Recommendation: The model would beneﬁt from better documentation of the modelling process, rationale for the algorithm selection, its ﬁtness for purpose, inclusion/ exclusion criteria for variables, etc. Systemic Bias Systemic bias is the inherent tendency of a process to support speciﬁc outcomes. In this mode, social vulnerability and poverty data are not substantially disaggregated. The move from 'common dataset' to 'composite dataset' involved ranking of variables. ● Recommendation: Clarity, rationale and disaggregation of parameters like social vulnerability and poverty would be beneﬁcial. Clarity required in relative weights of variables when ranking.