--- Page 0 ---
Predictive Analytics for Anticipatory Action: Challenges and Opportunities by Nicholas Bodanac 2020 Data Fellow (Predictive Analytics) OCHA Centre for Humanitarian Data December 2020

--- Page 1 ---
T a b l e o f C o n t e n t s Executive Summary 3 Introduction: Predictive Analytics in the Humanitarian Sector 5 Case Studies 6 FAO early warning early action for drought and food security in Colombia and Sudan 6 OCHA Bangladesh early action river flood mechanism 9 Implementing Predictive Analytics in Support of Anticipatory Action 1 ​ 2 Recommendations and Conclusion 19 References 2 ​ 1 Acknowledgements The research for this report was conducted by Nicholas Bodanac in June and July 2020 as part of the OCHA Centre for Humanitarian Data’s Data Fellows Programme. The research was supervised by Stuart Campo, the lead for the Data Fellows Programme; and Leonardo Milano, team lead for predictive analytics at the Centre. The findings and recommendations draw primarily on interviews with key informants from FAO, IFRC, OCHA and the START Network. Key informants were interviewed on specific projects in Colombia, Sudan, and Bangladesh, while also providing overall guidance of how the sector is utilizing predictive analytics. The author gratefully acknowledges the inputs and feedback from everyone involved in this research. The research findings are presented in a descriptive manner based on the author’s analysis. Given the limited duration of the research and relatively small number of key informants, the findings should not be considered to be representative of the entire humanitarian sector. of 22

--- Page 2 ---
E x e c u t i v e S u m m a r y In June and July 2020, the United Nations Office for the Coordination of Humanitarian Affairs (OCHA) Centre for Humanitarian Data conducted research through its Data Fellows Programme to better understand the ​ existing processes ​ for implementing predictive analytics in humanitarian action. Through this research, the Centre aimed to answer the following questions: 1 ● What are the emerging ​ best practices ​ for model development and use? ● What ​ pitfalls do organizations face ​ in using predictive models for anticipatory action? ● How can we ​ improve the implementation ​ of predictive analytics in humanitarian settings? The research consisted of a literature review, a series of key informant interviews, and the development of case studies. The literature review focused on technical academic papers, humanitarian project documents, and independent reviews of the application of predictive analytics within the development and humanitarian sectors. (A complete list of resources reviewed is included at the end of this paper ​ ) ​ . The key informant interviews involved individuals working on predictive analytics with four humanitarian organizations: the International Federation of the Red Cross and Red Crescent Societies (IFRC), the START Network, the Food and Agriculture Organization of the United Nations (FAO), and the United Nations Office for the Coordination of Humanitarian Affairs (OCHA). The case studies cover FAO-led pilots in Colombia and Sudan and an OCHA-led pilot in Bangladesh. The key findings from the research are as follows: ● Many organizations are ​ not clear on the questions driving modeling work ​ and how predictive analytics fits into their overall situational awareness. ● Many organizations have ​ insufficient expertise ​ related to the technical development, contextual adaptation, and programmatic use of models. This ​ may lead to inefficient or inaccurate model development ​ and could also ​ present ethical concerns ​ . ● Local participation is essential ​ in the design and ownership of predictive models, but is often overlooked or underdeveloped ​ . ● Organizations often neglect or fail to properly implement technical review phases ​ . In some cases, this has led to the implementation of inaccurate models. 1 These questions are based on inputs from the ​ Early Action Focus Task Force ​ , a group of key stakeholders (FAO, IFRC, OCHA, the START Network, and WFP) to ensure collaboration and coherence in anticipatory action in the sector. of 22

--- Page 3 ---
● Significant challenges persist in relation to ​ data gaps/availability and quality ​ , limiting the viability and accuracy of model development. Based on these findings, the Centre offers the following six recommendations for improving the implementation of predictive models in support of anticipatory action: Invest in filling data gaps and ensuring that data used for modeling is accurate and complete. ​ Accurate data is key to rigorous model development. Predictive models built on incomplete or inaccurate data are of little use. While proxy information such as remote sensing can be helpful in some circumstances, there is a need to invest in primary data gathering to further enhance a model’s accuracy. Involve technical partners, local stakeholders and implementing organizations in the development of triggers and related disaster risk financing frameworks. ​ This can improve accuracy of models and foster buy-in for models by local governments and other stakeholders. Build and retain internal technical capacity for model development and use. ​ Internal technical capacity should complement working with technical partners and is beneficial to accurately develop models, but also to ensure oversight throughout the program life-cycle. Use predictive models in conjunction with traditional methods of analysis and evaluation. ​ While predictive models can highlight the onset of a shock, they should be used alongside other methods such as needs assessments and community perception surveys. Ensure that trigger mechanisms are linked to financial plans. ​ The development of standard operating procedures regarding the financial response to a trigger will help avoid delays once a trigger is activated. Engage in multi stakeholder peer review processes with technical and local partners ​ . This can help ensure the modeling is both technically sound and also reflective of the local context. of 22

--- Page 4 ---
I n t r o d u c t i o n : P r e d i c t i v e A n a l y t i c s i n t h e H u m a n i t a r i a n S e c t o r Predictive analytics refers to the use of current and past data to make forecasts about future events. This growing area of analysis includes the application of a range of statistical methods such as big data analysis, machine learning and other modelling techniques that are currently used across a range of disciplines inside and outside of the humanitarian sector. Humanitarian action has generally been undertaken in response to a shock or crisis, which can lead to increased costs and a delayed response. As the United Nations ​ ​ Under-Secretary-General for Humanitarian Affairs Mark Lowcock has said, humanitarian response is “typically provided only after a disaster is in full swing… suffering is widespread by then… it costs perhaps 50 times as much to save a child who is already suffering from malnutrition as it does to intervene earlier". The implementation 2 of anticipatory action has the potential to improve the efficiency and speed of humanitarian response. While this is a relatively new area for the sector, a number of humanitarian organizations, including IFRC, FAO, the World Health Organization (WHO) and Médecins Sans Frontières ​ , ​ have implemented predictive modelling in response to hazards, migration, disease and famine for many years. For example, the IFRC has progressively developed and improved its forecast-based financing systems since 2008. As one key informant noted, “there is now new political interest in engaging and building 3 on the work previously conducted” to better integrate predictive analytics within the sector. Predictive models are particularly well-suited to supporting anticipatory action frameworks. Anticipatory action relies on forecasts to trigger funding for predetermined actions ahead of a shock. The aim is to reduce or mitigate the impact of social, environmental or conflict shocks and improve humanitarian response to a crisis. Such frameworks are already in use by a range of organizations and financing mechanisms in the sector, including forecast-based financing, the IFRC Disaster Relief Emergency Fund ( ​ DREF ​ ), the UN’s Central Emergency Response Fund ( ​ CERF ​ ), FAO’s Early Warning Early Action ( ​ EWEA ​ ), and the World Food Programme (WFP)’s ​ Emergency Preparedness and Response ​ . As of September 2020, there were at least 49 initiatives in the humanitarian sector using predictive 4 methods within their anticipatory action frameworks to inform humanitarian response. (See the Centre’s ​ Catalogue of Predictive Models ​ to learn more about who is doing what where in the sector). Although organizations have invested significantly in advancing their understanding and use of predictive methods, the implementation of predictive modelling thus far has not been uniform nor sufficiently rigorous in many cases. This poses a risk for the application of predictive analytics in the sector. Models which are not designed, evaluated, updated or understood properly provide limited value to decision makers. Further, the incorrect implementation of models and perceived lack of accuracy may cause stakeholders to withdraw support for such methods. 2 ​ https://www.unocha.org/story/un-humanitarian-chief-release-140m-cerf-funds-anticipatory-action-projects 3 Feasibility study on forecast based financing / trigger based action in Malawi, ECHO funded project: Enhancing resilience in Malawi, ​ https://europa.eu/capacity4dev/file/74963/download?token=VXaNAvVU 4 Hernandez, K. and Roberts, T. (2020). Predictive Analytics in Humanitarian Action: a preliminary mapping and analysis. K4D Emerging Issues Report 33. Brighton, UK: Institute of Development Studies. ​ https://opendocs.ids.ac.uk/opendocs/handle/ 500.12413/15455 of 22

--- Page 5 ---
C a s e S t u d i e s The Centre documented the process of a number of pilot projects as part of the research for this paper. The examples are presented through a common structure that examines four steps in the model process: initiation, development, validation, and application. This progression was also used to structure the key informant interviews as a way of better understanding and documenting current practice. While not part of this report, the Centre has also documented how models are maintained and how projections are kept relevant and up-to-date. We have looked at how model inputs are updated and who is responsible for that, how the accuracy of the model is assessed over time as new projections are produced, and who is in charge of monitoring model outputs and sending the trigger signal. We have also documented the roles and responsibilities that different stakeholders have in the process of development and use of predictive analytics. Figure 1: Steps in model development and use FAO early warning early action for drought and food security in Colombia and Sudan In both of the case studies presented below, FAO combined forecasting tools either developed by third parties or their own teams mixed with baseline and community assessments to trigger anticipatory action frameworks. Colombia La Guajira is the driest province of Colombia and many communities have struggled with a history of chronic food insecurity and malnutrition, which has been compounded by the migration crisis from Venezuela. Step 1: Initiation To understand the impact of migration on Colombia’s rural communities, FAO conducted a joint mission in June 2018 with WFP and the United Nations Children’s Fund (UNICEF) into the departments of La Guajira, Arauca and Norte de Santander. La Guajira was identified as the area of most concern, and consequently was chosen as the pilot location for an early warning early action project. According to FAO staff interviewed, La Guajira was particularly worrying. Findings showed how migration was already affecting food security. FAO complemented these findings with forward-looking analysis to anticipate how food security trends might develop. As opposed to building a model, FAO based their assessment on existing information from other agencies as well as data coming from primary information gathered during their joint mission in June 2018, specifically of 22

--- Page 6 ---
from interviews with local people in La Guajira. This covered issues with inputs to agricultural production, increasing local population and access to water. The information from these assessments pointed to a high likelihood of food security deterioration, according to FAO staff. Step 2: Development While FAO didn’t use a model for migration or to measure agricultural production, they did apply a trigger mechanism based on the onset of drought. Following review of several models from differing agencies, forecasting was used based on drought modelling from the International Research Institute for Climate and Society. The trigger assigned to the drought model was set at a probability of more than 50% of having below normal rainfall between July to October. This time-period is particularly crucial for crop planting in La Guajira. Step 3: Validation While FAO uses triggers to activate early action, they are always combined with some form of human judgement and analysis to validate the trigger system. Consequently, although the drought probability activated the trigger, it was combined with the assessment conducted in June 2018 and presented for a decision by the local country office. Given FAO did not have a full-capacity country office in Colombia compared to other areas, the processes used in this case were not representative of all FAO EWEA systems. In other countries where a full system is in place with regular monthly monitoring, the definition of thresholds and triggers and the combination of different indicators is more structured. FAO combines vulnerability measurements, forecasts and indicators of the agricultural season to periodically assess how it is progressing and what changes may need to be incorporated within early warning early action frameworks. When monitoring slow onset events such as drought, some early signs can be detected using remote sensing or other techniques. This can assist some livelihood groups. Step 4: Application While inputs for the model’s development were agreed upon by a committee of internal and external experts, the country office is responsible for and always operates the trigger, according to FAO staff. Country offices are responsible for producing the evidence for the release of the funds via the Special Fund for Emergency and Rehabilitation (SFERA) frameworks. According to FAO staff, funds are released once the trigger is reached. FAO has outlined standard operating procedures which dictate the processes and decisions that country offices and other relevant stakeholders need to take because of this index score and trigger activation. Decision making guidelines are also implemented on the level of probability. A probability of 0-40% will lead to no response, 40-60% will trigger an assessment and 60% or more leads to acting as soon as possible. In the case of La Guajira, a trigger attached to 50% was activated, after which an application for SFERA funding was developed. This request was submitted to a review board combined with the primary assessments conducted during the initiation phase. of 22

--- Page 7 ---
Sudan The project in Sudan was designed to monitor the risk of drought and dry spells in Kassala and Darfur. FAO identified worrying signs of drought in 2017 based on two specific indicators: unusual livestock movement and extended dry spells. Step 1: Initiation FAO’s primary objective was to anticipate drought and the impacts on the most vulnerable populations in the selected communities. The approach and analytical framework took into account all the meteorological and climatological indicators available for the local context which could be used for drought modelling and combined them with a range of socio-economic indicators, such as prices and terms of trade (livestock, maize, etc.). Step 2: Development FAO mapped existing indicators and sources of information and compiled three datasets which included a climate outlook and climate conditions. Assessments were conducted on the reliability and availability of indicators based on the local agricultural season. Following this, the initial list of 40-60 measurable indicators was narrowed down to a list of just 15. This process was conducted in consultation with local partners including participants from the head of the national early warning system and the head of a pastoralist group in a village of concern. It was important that representatives of national, regional and local levels, as well as beneficiaries were included within this process. Step 3: Validation Following the consultation process, the country office conducted consultations with HQ-based technical experts to review the index construction and weights and to conduct a deeper analysis on some of the thresholds. The tools were then tested with simulations going back one to two years to see how accurate the results would be. According to FAO staff: “when testing the composite score of 0-100, we wanted to know what a normal record delivered, a score of 50, 60, 70? And from this information, the triggers were re-calibrated”. Step 4: Application The tool was designed to be simple and have zero cost for local stakeholders. It was built in Microsoft Excel and each month new data would be collected and analyzed and then the results would be discussed with the partners. The thresholds were triggered towards the end of the harvest season, highlighting a localized drought. Like the example in Colombia, the results were combined with a field-level assessment that confirmed the model’s trigger activation. One area of improvement highlighted by FAO is the need to do a post-validation assessment of the tool. Although FAO could do more thorough statistical analysis, the availability of data about the local contexts makes it difficult to use time series data needed. Further, as tools are designed to be used by a non-expert at a zero cost, this also limits the technical capacity which goes into their development. of 22

--- Page 8 ---
OCHA Bangladesh early action river flood mechanism In early 2020, the UN Emergency Relief Coordinator, Mark Lowcock, set aside $140 million in CERF funding for anticipatory action pilot mechanisms focusing on drought in Somalia, Ethiopia, Malawi and Chad; cholera outbreaks in sub-Saharan Africa; and floods in Bangladesh. According to staff 5 interviewed, the goal was to use forecasting measurements with high confidence levels that could be tied to pre-arranged financing mechanisms in order to mitigate the effects of a shock. Under the leadership of the UN Resident Coordinator, the objective of the pilot in Bangladesh was to implement a more effective response in anticipation of severe monsoon flooding of the Jamuna River. Specifically, the pilot focused on the five highly-vulnerable districts of Bogura, Gaibandha, Kurigram, Jamalpur, and Sirajgonj. Step 1: Initiation In the case of Bangladesh, OCHA assessed a range of hazards for whether and how models could be applied to drive an anticipatory response. These included drought, disease outbreak, monsoon floods, earthquakes, and volcanic eruptions. It was decided that focusing on monsoon floods was most appropriate, given that flood warning systems had already been developed for the entire country and allowed for sufficient lead time between the initial trigger (based on a 10-day forecast) and the actual activation, which aligned with OCHA’s pilot framework for anticipatory action. Step 2: Development OCHA decided to make use of models that were already developed, and tailor them to fit the localized frameworks. A technical team assessed a range of models that were developed with high levels of confidence and were verifiable. This included the Centre for Humanitarian Data's predictive analytics team which provided technical support to analyze and validate the thresholds and triggers for the release of funds from the CERF. According to an informant: “A key element of the model design phase was to build as much as possible on models already reviewed and designed to ensure their accuracy was sound". As there are several flood forecasting systems in use for Bangladesh already, there were a number of possibilities to choose from. For example, the local government has several forecasting tools, however, they are all based on a 5-day forecast. The European Commission’s Global Flood Awareness System (GloFAS) flood assessment system includes a 10-day probabilistic forecast and consequently was chosen. The model produces daily probabilistic forecasts 10, 15 and 30 days into the future. The forecasts also include the size of the flood, for example a one in five-year flood, one in ten years, or one in twenty-year event taking place. It was decided that a dual-model system was to be used, one as a pre-activation warning for preparedness and readiness followed by a final activation system. 5 UN humanitarian chief to release up to $140M in CERF funds for anticipatory-action projects, 25 June, 2020 ​ : https://www.unocha.org/story/un-humanitarian-chief-release-140m-cerf-funds-anticipatory-action-projects of 22

--- Page 9 ---
Step 3: Validation Once selected, the models needed to be adjusted to fit the environment and context. Historical data was difficult to acquire and consequently, a technical team had to come to a solution of how to optimize the information they had. The Centre’s predictive analytics team also helped with identifying and implementing better triggers that would fit the local context. This included optimizing the thresholds in collaboration with a technical team of local experts, Bangladesh Red Crescent Society (BDRCS) and OCHA team members. The basis of a two-trigger system was that a pre-activation is 40% likely to be followed by an activation. Consequently the activation system was developed with the following two measurements: ● First, a 10-day probabilistic warning model based on GloFAS, a global hydrological forecast and monitoring system that couples weather forecasts with a hydrological model and is calibrated for the Jamuna river in Bangladesh. ● Second, a 5-day deterministic action model, based on the Bangladesh Flood Forecast & Warning Center. Step 4: Application In Bangladesh, the BDRCS employs a scientific team to monitor early warning systems for the entire country. It was noted by OCHA staff that when the scientists flagged the trigger’s activation, the response was immediate with funds being released within hours. It was purposefully planned that no review or committee or decision was needed following the triggers activation, to ensure the rapid response needed for such an event. A strategy was developed around the two different triggers. First, the initial 10-day trigger activation system would release all funds ($5 million) for an initial early action response, following which a response was planned and ready for immediate deployment based on a secondary 5-day trigger mechanism. During this phase, $5 million was released from CERF funding prioritized for early action systems. The funding systems were divided among the relevant agencies as follows: $4.25 million for WFP, including a sub-grant to BDRCS; $500,000 to FAO; and $589,084 for the United Nations Population Fund (UNFPA). It was agreed that there would be no discussion within the program team on what funds were spent and a no regrets approach would be implemented. While there was a limited time-period leading to the 2020 flood season and limited resources, the pilot was able to include three main components. First, together with WFP and the BDRCS, 61,500 vulnerable households were to receive US$53 each ahead of a flood (55,500 households via WFP and 6,000 households via BDRCS. While the actual number of households assisted was just 23,000, this was more of a reflection of the outdated population lists used for the vulnerability assessment, which made it difficult to accurately assess the population in need. The FAO also supported 14,000 households with livestock protection and flood-proof storage of agricultural and productive assets of 22

--- Page 10 ---
(e.g. tools, seeds). Also, UNFPA distributed reproductive health, menstrual hygiene and dignity kits to some 14,922 vulnerable women and girls. The Bangladesh pilot offers valuable opportunities to learn and to advocate for an expansion of the reach of the anticipatory action so that larger populations at imminent risk can be assisted. OCHA has commissioned an independent evaluation of the individual components of the pilot. The results are expected to be released around March 2021. of 22

--- Page 11 ---
I m p l e m e n t i n g P r e d i c t i v e A n a l y t i c s i n S u p p o r t o f A n t i c i p a t o r y A c t i o n This section presents key findings and recommendations on the implementation of predictive 6 analytics in support of anticipatory action. It presents more detailed observations across the different stages of model development. It includes a set of questions or considerations for organizations to consider at these different stages in order to overcome some of the challenges identified through the research. These considerations are also summarized in a decision-tree format in Figure 2 below. Figure 2: Key considerations in the model life cycle 6 The findings and recommendations draw primarily on interviews with key informants from FAO, IFRC, OCHA and the START Network. Key informants were interviewed on specific projects in Colombia, Sudan and Bangladesh, while also providing overall guidance of how the sector is utilizing predictive analytics. of 22

--- Page 12 ---
Step 1: Model Initiation According to one key informant, “You can’t wait for the good models to be in place before you start moving in that direction [predictive modelling], it has to be done in parallel [with methodological developments]”. Another key informant stated, “There are still challenges in terms of not setting things up early enough, however, this is currently improving”. When there is a disease outbreak, for example, models must be developed rapidly to estimate the spread of disease or a virus. The risk of waiting far outweighs the time needed to develop more accuracy and consequently strict review processes are often put to the side in favor of a more rapid forecasting. Waiting too long also has the obvious negative effect of unnecessarily extending the human suffering early action is meant to prevent. However, often in these cases, academic partners 7 or research bodies are brought into develop forecasts for humanitarian implementers given their research is already bounded in peer reviewed frameworks or developed by experts within their field. From a basic economic point of view, it is often costlier to wait too long than to act too early. While there have been some examples of negative economic effects tied to incorrect forecasts. For example, seasonal forecasts in 1998 led farmers to reduce their cropping area in southern Africa, as they interpreted the forecast as a probability of drought rather than an increased chance of below-average rainfall. However, EWEA programs in Sudan implemented by FAO produced a cost benefit ratio of 6.7, 8 meaning that for every USD 1 invested by FAO, households gained USD 6.7. The unit cost of food aid 9 can be cut by 30% if procured early, according to a study on aid delivery to Somalia, Kenya and Ethiopia. Also, ‘acting in vain’ has been justified by a ‘no regrets’ implementation strategy, meaning 10 that spending on people and places that are poor and climate-vulnerable anyway can enhance 7 Hillier and Dempsey, 2012. A Dangerous Delay: The cost of late response to early warnings in the 2011 drought in the Horn of Africa. ​ https://www.researchgate.net/publication/263725932_A_Dangerous_Delay_The_cost_of_ late_response_to_early_warnings_in_the_2011_drought_in_the_Horn_of_Africa 8 Dilley, M.: Reducing vulnerability to climate variability in Southern Africa: The growing role of climate information, Climatic Change, 45, 63–73, 2000, ​ https://link.springer.com/article/10.1023/A:1005636932536 9 The Sudan, Impact of Early Warning Early Action, ​ http://www.fao.org/3/ca4653en/ca4653en.pdf 10 The Economics of Early Response and Resilience: Approach and Methodology Cabot Venton, 2013. Economics of Resilience. ​ https://assets.publishing.service.gov.uk/media/57a08a0ae5274a31e00003c0/61114_Approach_ and_Methodology.pdf of 22 At this stage, organizations should consider: ● What is the problem we are trying to solve? ● Why can’t we solve it with current methods of analysis? ● Does predictive modelling fill this gap? ● Is there available data to use for a model?

--- Page 13 ---
resilience to future shocks. However, there are significant financial risks associated with predictive 11 models that can’t be ignored. As predictive analytics gains further attention there is an urge for organizations to implement models without understanding when this is appropriate. Often, organizations start with the mindset of ‘we’re going to build a famine model’ or ‘we’re going to build a drought model’ without understanding whether this is the best way to measure and respond to that particular crisis or shock, or if predictive models are even feasible given the data landscape. Based on the research, integrating predictive approaches is best after an analysis of what the major gaps are in traditional research methods or current use of forecasting. At times, limitations or inaccuracies may be from capacity issues, a lack of localized data, or, poor program management. Engaging with local representatives and assessing the local context is key. This can assist in knowing these limitations or strengths can greatly enhance model development and help to direct efforts in the most efficient way. Data gaps limit how models can be developed. Most organizations using predictive analytics still rely on their own data collection or the use of open source data form local governments and other organizations. While this is beneficial for some cases, such as WFP’s food security data, in other cases 12 there are significant gaps especially at the local level. Predictive models are dependent on the quality of the data sets on which the models operate and consequently sound data is essential for quality forecasting methods. Understanding the data landscape and the limitations with available methods 13 is key to deciding whether and, if so, how to utilize predictive models. ​ As noted, data availability greatly limits a model’s accuracy and ability to effectively develop early warning models. As one informant noted, “people are developing models without asking questions of what data is going in it. A model is only as good as the information that it feeds off”. Where data gaps exist, it may be tempting for organizations to fill these gaps with proxy information or questionable research methods. The concern of using ‘bad data’ was highlighted by those interviewed who stated that the use of models with bad data or inaccurate information is “completely useless”. There needs to be a more concerted effort to ensure sound practice in sourcing data for use in modeling. Organizations need to understand the data landscape and key actors who may be able to help fill data gaps. ​ While remote sensing is used in cases to mitigate this issue, there are limited uses of data collection methods like satellite imagery and other proxy data methods. For example, satellite imagery can provide information on crop patterns but may not deliver information on household 11 ODI Working Paper 547, Scaling Up Early Action, April 2019, ​ https://www.odi.org/sites/odi.org.uk/files/ resource-documents/12641.pdf 12 Hernandez, K. and Roberts, T. (2020). Predictive Analytics in Humanitarian Action: a preliminary mapping and analysis. K4D Emerging Issues Report 33. Brighton, UK: Institute of Development Studies. ​ https://opendocs. ids.ac.uk/opendocs/handle/20.500.12413/15455 13 Predictive analytics in humanitarian action: a preliminary mapping and analysis, K4D, June 2020 ​ https:// assets.publishing.service.gov.uk/media/5f0c877ce90e070313365f0d/EIR33_Humanitarian_Predictive_Analytics.pdf of 22

--- Page 14 ---
economic systems. Further, due to a lack of fishery survey data, predictive models have been used to 14 forecast yield estimates in tropical river and lake fisheries using simple multiple linear regression estimates. However, these models were imprecise and had large error terms. Consequently, while 15 they were used as a next best estimate their reliability is questionable. Processes need to be put in place and followed to ensure accurate measurements are being applied to direct humanitarian response. ​ To assist on this, organizations like FAO have used mixed methods approaches by combining local data collection in target communities in conjunction with forecasting methods to see how the two interact, and to provide better guidance. When designing predictive models, it’s important to understand that their purpose isn’t to be a silver bullet that can take over the sector, rather, as a way of complimenting approaches currently in place. One key informant stated, “humanitarian decisions should not be made alone on predictive analytics. They can support existing approaches”. Organizations like IFRC and FAO use predictive models and forecasts in conjunction with other more standard evaluation methods like baseline assessments and community engagement programs. Step 2: Model Development Predictive models are often implemented to fill a gap, such as a lack of understanding or capacity to measure a shock which leaves humanitarians unprepared or late to assist populations in need. Identifying the source of these gaps can help organizations understand if predictive models are an appropriate tool to fill them. One informant noted “there is a lot of effort and time expended in developing a model without even consulting humanitarian technical experts on the ground. What is being asked or what data is being fed into it?”. Developing and reviewing predictive models effectively requires a mix of technical, quantitative, programmatic, and contextual expertise. When developing a model for a particular context and use 14 AIMS pilot project. Monitoring the rehabilitation of degraded landscapes from Food Assistance for Assets programmes with satellite imagery, September 2017. ​ https://docs.wfp.org/api/documents/WFP-0000099680/download/?_ga=2.126610821. 1579025626-1204141535.1578873829 15 FAO predictive yield models for tropical river and lake fisheries, 2006. ​ http://www.fao.org/3/ca4475en/ca4475en.pdf of 22 In this stage, organizations should consider: ● How can a model compliment existing approaches? ● Do we have the capacity required to develop and review models? ● What needs to be outsourced/partnered to develop or review models? ● How can we involve local stakeholders in model development? ● How to develop an initial review committee?

--- Page 15 ---
case, organizations need to consider whether they have the capacities required across these areas.On the technical and quantitative dimension, organizations do not need to internalize all processes themselves. In fact, attempting to do so can deliver poor results for organizations that do not hold the qualification to develop and review predictive and forecasting models. If an organization lacks the technical capacity to develop its own models, building partnerships with external technical teams is a much better solution than attempting the estimations without proper oversight or review. On the programmatic and contextual dimension, organizations need to learn from those with experience in the particular country of interest. Model developers may misjudge or fail to account for variables or local dynamics, just as humanitarians on the ground may misjudge the implications of different forecasting measures, or not have the specific knowledge required to design forecasting measures for a particular context. The Centre for Humanitarian Data’s ​ Peer Review Framework ​ ​ aims to increase such adaptive measures and to ensure that model structures are followed. Such frameworks can bring in outside thought and expert review early on in the design phase and help direct a model’s development and accuracy. Partnering with local teams, governments and organizations is key to effective model development. All those interviewed acknowledged the importance of understanding local dynamics. One informant stated that there is a need for a more coherent approach in working with local governments and communities. Working directly with local teams was also highlighted by epidemiologists as a huge benefit for overall quality and accuracy. Step 3: Model Validation Model validation should highlight the strengths and weaknesses of the model as well as its proposed use. There is currently no uniform evaluation process with predictive analytics. While some agencies and organizations have stringent methodologies, others are yet to implement stringent approaches and evaluation methods. Once models have been developed, they need to be validated before they can be responsibly used. This process should sit within a technical team or be conducted through a holistic review process form a range of stakeholders. This could include the development of specific reviewers, or review committees, similar to a peer review process for academic research that can validate methods and variables included. of 22 At this stage, organizations should consider: ● What processes will be used to incorporate feedback from peer review? ● How will review processes be established throughout the model life cycle?

--- Page 16 ---
More consistent approaches to evaluating models before implementation are key to improving the overall accuracy, quality and relevance of predictive analytics in the sector. One informant noted organizations are still far away from this, but this should be a requirement for future projects”. This emphasizes the need for due diligence. A positive example of this is FAO’s method of validation and review. First, there is an initial consultation with key stakeholders during the inception phase, where measurements are reviewed and agreed upon by local stakeholders and partner organizations. Following the development of a risk index which is used as a trigger mechanism, a secondary review is also conducted by a team of internal technical experts. This includes testing the model with historical data, calibrating it, and reviewing methodologies before it is implemented within the program. Model validation is not a one off process. After ​ a model has been validated for its intended use case, it may need to be validated again as the context evolves and/or the implementation plan for the model and its outputs changes. ​ Data needs to be updated regularly and new information may require for models to be recalibrated. One informant noted, “In my two years working in anticipation design processes, very rarely have there been any kind of technical experts or risk modelers consistently involved (in the project life cycle)”. This leads to questions and risks over how accurate a model is if it’s review process stops at implementation. Having expert review and response integrated throughout the cycle can have an enormous effect on increasing the efficiency of a model and the accuracy of its outputs. As noted earlier, we can’t wait for models to be perfect before we implement. However, once they are being used, they still need regular work. Updating triggers with new data and testing the accuracy does not stop once they have been used. This means new methodologies need to be implemented, or new data inserted to test models accuracy and to keep them current. Step 4: Model Application The application of predictive models to support the implementation of anticipatory action frameworks is based on activating some form of response (financing, the delivery of assistance, etc.) tied to a trigger or warning mechanism. When a certain level of probability or risk is indicated, the release of financial support is often activated. of 22 At this stage, organizations should consider: ● How to increase a holistic approach to trigger development, including local ownership? ● How to enable rapid financial response following trigger activation? ● How to mitigate risk to ensure local and partner financial support?

--- Page 17 ---
Local ownership has become a key component for many early warning systems. Consequently having local agencies or local governments buy into the idea and commit financing will require these decisions to be made jointly with expert committees. As a result, the development of a trigger should be a joint effort by technical partners, local stakeholders and implementing organizations. For example, FAO country offices are responsible and always operate their trigger mechanisms, according to staff interviewed. These local offices are responsible for bringing the evidence for the release of the funds. However, these are based on consultations and local agreements with various local partners and committees to discuss trigger warning mechanisms and to ensure a holistic review process is developed at the beginning. When designing triggers, it’s also important to understand how they relate to the financial mechanisms of partner agencies. Some informants noted that developing triggers should be conducted through the ‘impacts before instruments’ idea. This focuses on what impacts can be achieved within their organization and within their capacity. Understanding operational capacity is key in outlining lead times needed and being able to accurately respond to a trigger. IFRC, for example, can deliver cash grants at the household level in Bangladesh within 4 days of a trigger. Once triggers have been activated, the time it takes for finances to be released can require significant time before assistance reaches the area of concern. There needs to be more of a focus toward response actions over “what can be moved, when and how?”. When likelihoods increase, different responses may be needed. Some agencies have response and finance deliverables in place to mitigate this lag and ensure rapid response reaches people in need as quickly as possible. As one informant stated, “There is no point having anticipatory models that are 100% accurate, if financial activation can be delayed for months”. This also needs to be planned with partner organizations who may work on much different time scales. Failure to accurately develop these financing agreements between partner organizations will significantly limit the use for early warning systems. of 22

--- Page 18 ---
R e c o m m e n d a t i o n s a n d C o n c l u s i o n Based on the research and analysis presented above, the Centre proposes the following six recommendations for improving the implementation of predictive analytics in support of anticipatory action. Invest in filling data gaps and ensure that quality data is used for modeling. ​ Accurate data is key to rigorous model development. Predictive models built on incomplete or inaccurate data are of little use. While proxy information such as remote sensing can be helpful in some circumstances, there is a need to invest in primary data gathering to further enhance a model’s accuracy. ​ ​ In the Bangladesh case study for example, government meteorological data was used, however, the government’s statistical site was prone to crashing. Involve technical partners, local stakeholders and implementing organizations in the development of triggers and related disaster risk financing frameworks. ​ This can improve accuracy of models and foster buy-in for models by local governments and other stakeholders. As local ownership is a key component to many early warning systems, having local participation within the design phase is essential. Build and retain internal technical capacity for model development and use. ​ Internal technical capacity should complement working with technical partners and is beneficial to accurately develop models, but also to ensure oversight throughout the program life-cycle. Use predictive models in conjunction with traditional methods of analysis and evaluation. ​ While predictive models can highlight the onset of a shock, they should be used alongside other methods such as needs assessments and community perception surveys. Models supported by other forms of analysis will lead to a better overall results and more accurate response. For example, organizations such as FAO use local rapid assessments to confirm their activation systems and minimize the risk of ‘activating in vain’. Ensure that trigger mechanisms are linked to financial plans. ​ The development of standard operating procedures regarding the financial response to a trigger will help avoid delays once a trigger is activated. The response to a trigger activation needs to be planned and agreed upon before or in conjunction with an early warning system. As many organizations are now taking a ‘no regrets’ approach, this will limit delays in programmatic response. The dual trigger system implemented by OCHA in Bangladesh is also a possibility for organizations looking to limit financial risk in this regard. Engage in multi stakeholder peer review processes with technical and local partners. ​ This can help ensure the modeling is both technically sound and also reflective of the local context. Ensuring that organizations have sound internal or external review systems covering the development and application of methodologies is essential to ensuring a model’s accuracy and, consequently, the quality of it’s predictions. of 22

--- Page 19 ---
The Centre will use the findings and recommendations of this research to support the growing number of organizations implementing predictive analytics for anticipatory action. We hope that this report will help to generate a constructive discussion with partners around the use of predictive analytics in humanitarian response. Building on the experience from the Bangladesh pilot, OCHA will be scaling up the number of anticipatory action frameworks in 2021 in collaboration with the CERF. The Centre will continue to document ‘who is doing what, where and when’ with predictive models in the ​ Catalogue of Predictive Models ​ and will support humanitarians to make the best use of predictive models through our ​ Peer Review Framework ​ . of 22

--- Page 20 ---
R e f e r e n c e s Annibale Vecere, Ricardo Monteiro, Sonia Giovianzzi, Raquel Henrique Melo Santos, ​ Predictive models for post disaster needs assessment, International Journal of disaster risk reduction ​ , November 2016 Cabot Venton, C, Economics of Resilience, ​ The Economics of Early Response and Resilience: Approach and Methodology ​ , 2013 Dilley, M., Reducing vulnerability to climate variability in Southern Africa: The growing role of climate information, ​ Climatic Change ​ , 45, 63–73, 2000 ECHO, ​ Feasibility study on forecast based financing / trigger based action in Malawi, ​ ECHO funded project: Enhancing resilience in Malaw ​ i FAO, ​ Colombia: Impact of Early Warning Early Action ​ , Rome, 2019 FAO, ​ Building stronger partnerships for resilience ​ , Rome, 2019 FAO, ​ Predictive yield models for tropical river and lake fisheries ​ , 2006 German Red Cross, ​ Forecast-Based financing; An innovative approach ​ , October 2017 German Red Cross, ​ Forecast-based financing Mozambique German Red Cross, ​ Forecast-based financing A policy overview ​ , October 2017 Institute of Development Studies, ​ Predictive Analytics in Humanitarian Action: A Preliminary Mapping and Analysis ​ , May 2020 Havard Higre et al., ​ Predicting Armed Conflict 2010-2050 ​ , November 2011 Hernandez, K. and Roberts, T. (2020). Predictive Analytics in Humanitarian Action: a preliminary mapping and analysis. ​ K4D Emerging Issues Report 33 ​ Brighton, UK: Institute of Development Studies. Hillier and Dempsey, 2012. ​ A Dangerous Delay: The cost of late response to early warnings in the 2011 drought in the Horn of Africa. IFRC ​ , IFRC Results based matrix: 2017 progress plan and budget ​ , 2017 IFRC ​ , Practical Information on Forecast based action by the DREF ​ , 2017 Junaid Qadir, Anwaar Ali, Raihan ur Rasool, Andrej Zwitter, Arjuna Sathiaseelan, Jon Crowcroft, ​ Crisis analytics Big data-driven crisis response ​ , Journal of international humanitarian action, 2006 of 22

--- Page 21 ---
NRC, IDMC, ​ Assessing drought displacement risk for Kenya, Ethiopian and Somali Pastoralists, technical paper, ​ April 2014 ODI, ​ Scaling up early action, Working paper 547 ​ , April 2019 ODI, ​ Anticipatory humanitarian action: What role for the CERF? ​ , April 2019 OCHA Centre for Humanitarian Data, ​ Peer Review Frameworks for Predictive Analytics in Humanitarian Response ​ , March 2020 UN CERF, ​ CERF and Anticipatory Action ​ , June 2019 WFP, AIMS pilot project. ​ Monitoring the Rehabilitation of Degraded Landscapes from Food Assistance for Assets Programmes with Satellite Imager ​ y, September 2017 of 22